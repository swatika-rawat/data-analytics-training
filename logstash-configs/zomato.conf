# Create index mapping for geo_point in Elasticsearch before executing logstash config
# PUT zomato
# {
#   "mappings": {
#     "properties": {
#       "lat_long": {
#         "type": "geo_point"
#       }
#     }
#   }
# }

input {
  file {
    path => "D:/elk/datasets/indian_restaurants_details_cleaned_data.csv"
    start_position => "beginning"
    sincedb_path => "NUL"
  }
}
filter {
  csv {
    separator => ","
    skip_header => "true"
    columns => ["zomato_url", "name", "city", "area", "rating", "rating_count", "telephone", "cusine", "cost_for_two", "address", "timings", "online_order", "table_reservation", "delivery_only", "famous_food", "longitude", "latitude"]
  }
  mutate {
    convert => {
      "rating" => "float"
      "rating_count" => "integer"
      "cost_for_two" => "float"
      "online_order" => "boolean"
      "table_reservation" => "boolean"
      "delivery_only" => "boolean"
      "latitude" => "float"
      "longitude" => "float"
    }
    rename => {
      "latitude" => "[lat_long][lat]"
      "longitude" => "[lat_long][lon]"
    }
  }
}
output {
  elasticsearch {
    hosts => "localhost:9200"
    index => "zomato"
  }
  stdout { }
}
